{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Data Science Capstone</h1>\n",
    "\n",
    "Maxwell Burner\n",
    "\n",
    "<p>This notebook will be used for my capstone project for the Coursera Data Science certificate Series.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from geopy.geocoders import Nominatim\n",
    "\n",
    "import requests\n",
    "\n",
    "import pydotplus\n",
    "\n",
    "from IPython.display import Image\n",
    "\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.colors as colors\n",
    "import matplotlib.image as mpimg\n",
    "from matplotlib import pyplot as py\n",
    "%matplotlib inline\n",
    "\n",
    "import sklearn.tree as tree\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.externals.six import StringIO\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "import folium"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I. Create Database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A. Create Database of Chicago Neighborhoods with Coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "Albany_Park = ['Albany Park','Mayfair','North Mayfair','Ravenswood Manor']\n",
    "Archer_Heights = ['Archer Heights']\n",
    "Armour_Square = ['Armour Square','Chinatown','Wentworth Gardens']\n",
    "Ashburn = ['Ashburn','Beverly View','Parkview','Scottsdale','Wrightwood']\n",
    "Auburn_Gresham = ['Gresham']\n",
    "Austin = ['Galewood','The Island','North Austin','South Austin','West Humboldt Park']\n",
    "Avalon_Park = ['Avalon Park','Marynook','Stony Island Park']\n",
    "Avondale = ['Avondale','Polish Village']\n",
    "Belmont_Cragin = ['Belmont Central','Brickyard','Cragin','Hanson Park']\n",
    "Beverly  = ['Beverly','East Beverly','West Beverly']\n",
    "Bridgeport = ['Bridgeport']\n",
    "Brighton_Park = ['Brighton Park']\n",
    "Burnside = ['Burnside']\n",
    "Calumet_Heights = ['Calumet Heights','Pill Hill']\n",
    "Chatham = ['Chatham','East Chatham','West Chatham']\n",
    "Chicago_Lawn = ['Chicago Lawn','Lithuanian Plaza','Marquette Park']\n",
    "Clearing = ['Chrysler Village','Clearing East','Clearing West']\n",
    "Douglas = ['Bronzeville','Dearborn Homes','The Gap','Groveland Park','Lake Meadows','Prairie Shores','South Commons',\n",
    "          'Stateway Gardens']\n",
    "Dunning = ['Dunning','Irving Woods','Schorsch Village']\n",
    "East_Garfield_Park = ['East Garfield Park','Fifth City']\n",
    "East_Side = ['East Side']\n",
    "Edgewater = ['Andersonville','Edgewater','Edgewater Beach','Edgewater Glen','Lakewood']\n",
    "Edison_Park = ['Edison Park']\n",
    "Englewood = ['Englewood', 'Hamilton Park']\n",
    "Forest_Glen = ['Edgebrook','Forest Glen','Old Edgebrook','Sauganash','South Edgebrook','Wildwood']\n",
    "Fuller_Park = ['Fuller Park']\n",
    "Gage_Park = ['Gage Park']\n",
    "Garfield_Ridge = ['Garfield Ridge','LeClaire Courts','Sleepy Hollow','Vittum Park']\n",
    "Grand_Boulevard = ['Grand Boulevard','Legends South']\n",
    "Greater_Grand_Crossing = ['Grand Crossing','Greater Grand Crossing','Park Manor']\n",
    "Hegewisch = ['Hegewisch']\n",
    "Hermosa = ['Belmont Gardens','Hermosa','Kelvyn Park']\n",
    "Humboldt_Park = ['Humboldt Park']\n",
    "Hyde_Park = ['East Hyde Park','Hyde Park']\n",
    "Irving_Park = ['Avondale Gardens','Irving Park','Kilbourn Park','Merchant Park','Old Irving Park','The Villa']\n",
    "Jefferson_Park = ['Gladstone Park','Jefferson Park']\n",
    "Kenwood = ['Kenwood', 'North Kenwood']\n",
    "Lake_View = ['Boystown','Graceland West','Lake View','Lake View East','North Halsted','South East Ravenswood',\n",
    "            'West Lakeview','Wrigleyville']\n",
    "Lincoln_Park = ['Lincoln Park','Park West','Range Triangle','Sheffield Neighbors','West DePaul',\n",
    "               'Wrightwood Neighbors']\n",
    "Lincoln_Square = ['Bowmanville','Budlong Woods','Lincoln Square','Ravenswood','Ravenswood Gardens']\n",
    "Logan_Square = ['Bucktown', 'Kosciuszko Park','Logan Square','Palmer Square']\n",
    "Lower_West_Side = ['East Pilsen','Heart of Chicago','Lower West Side','Pilsen']\n",
    "McKinley_Park = ['McKinley Park']\n",
    "Montclare = ['Montclare']\n",
    "Morgan_Park = ['Beverly Woods','Morgan Park','Kennedy Park','West Morgan Park']\n",
    "Mount_Greenwood = ['Mount Greenwood','Talley\\'s Corner']\n",
    "Near_North_Side = ['Cabrini-Green','Gold Coast','Goose Island','Magnificent Mile','Near North Side','Old Town',\n",
    "                  'River North','Streeterville']\n",
    "Near_South_Side = ['Central Station','Dearborn Park','Museum Campus','Prairie Avenue Historic District']\n",
    "Near_West_Side = ['Fulton River District','Greektown','Illinois Medical District','Little Italy','Near West Side',\n",
    "                 'Tri-Taylor','University Village','West Loop']\n",
    "New_City = ['Back of the Yards','Canaryville','New City']\n",
    "North_Center = ['North Center', 'Roscoe Village', 'Saint Ben\\'s']\n",
    "North_Lawndale = ['Douglas Park', 'Homan Square','K-Town','North Lawndale']\n",
    "North_Park = ['Hollywood Park','North Park','River\\'s Edge',]\n",
    "Norwood_Park = ['Big Oaks','Norwood Park East','Norwood Park West','Old Norwood','Oriole Park','Union Ridge']\n",
    "O_Hare = ['O\\'Hare','Schorsch Forest View']\n",
    "Oakland = ['Oakland']\n",
    "Portage_Park = ['Portage Park']\n",
    "Pullman = ['Cottage Grove Heights','Pullman']\n",
    "Riverdale = ['Altgeld Gardens','Eden Green','Golden Gate','Riverdale']\n",
    "Rogers_Park = ['Loyola','Rogers Park']\n",
    "Roseland = ['Fernwood','Kensington','Lilydale','Princeton Park','Roseland','Rosemoor']\n",
    "South_Chicago = ['South Chicago']\n",
    "South_Deering = ['South Deering']\n",
    "South_Lawndale = ['Little Village','Marhsall Square','South Lawndale']\n",
    "South_Shore = ['Jackson Park Highlands','South Shore']\n",
    "The_Loop = ['The Loop','New Eastside','Printer\\'s Row','South Loop']\n",
    "Uptown = ['Buena Park','Clarendon Park','Margate Park','New Chinatown','Sheridan Park','Uptown']\n",
    "Washington_Heights = ['Brainerd','Longwood Manor','Washington Heights']\n",
    "Washington_Park = ['Washington Park']\n",
    "West_Elsdon = ['West Elsdon']\n",
    "West_Englewood = ['West Englewood']\n",
    "West_Garfield_Park = ['West Garfield Park']\n",
    "West_Lawn =['Ford City', 'West Lawn']\n",
    "West_Pullman = ['West Pullman']\n",
    "West_Ridge = ['Nortown','Peterson Park','Rosehill','West Ridge','West Rogers Park']\n",
    "West_Town = ['East Village',' Noble Square', 'Pulaski Park','River West','Smith Park','Ukrainian Village', 'West Town',\n",
    "            'Wicker Park','Polish Triangle']\n",
    "Woodlawn = ['Woodlawn','West Woodlawn']\n",
    "community_areas = {'Albany Park':Albany_Park,'Archer Heights':Archer_Heights,'Armour Square':Armour_Square,'Ashburn':Ashburn,\n",
    "                   'Auburn Gresham':Auburn_Gresham,'Austin':Austin,'Avalon Park':Avalon_Park,\n",
    "                  'Avondale':Avondale,'Belmont Cragin':Belmont_Cragin,'Beverly':Beverly,'Bridgeport':Bridgeport,\n",
    "                   'Brighton Park':Brighton_Park,'Burnside':Burnside,'Calumet Heights':Calumet_Heights,\n",
    "                  'Chatham':Chatham,'Chicago Lawn':Chicago_Lawn,'Clearing':Clearing,'Douglas':Douglas,'Dunning':Dunning,\n",
    "                   'East Garfield Park':East_Garfield_Park,'East Side':East_Side,'Edgewater':Edgewater,\n",
    "                   'Edison Park':Edison_Park,'Englewood':Englewood,'Forest Glen':Forest_Glen,'Fuller Park':Fuller_Park,\n",
    "                   'Gage Park':Gage_Park,'Garfield Ridge':Garfield_Ridge,'Grand Boulevard':Grand_Boulevard,\n",
    "                  'Greater Grand Crossing':Greater_Grand_Crossing, 'Hegewisch':Hegewisch,'Hermosa':Hermosa,\n",
    "                   'Humboldt Park':Humboldt_Park,'Irving Park':Irving_Park,'Jefferson Park':Jefferson_Park,\n",
    "                  'Kenwood':Kenwood,'Lake View':Lake_View,'Lincoln Park':Lincoln_Park,'Lincoln Square':Lincoln_Square,\n",
    "                   'Logan Square':Logan_Square,'Lower West Side':Lower_West_Side,'McKinley Park':McKinley_Park,\n",
    "                  'Montclare':Montclare,'Morgan Park':Morgan_Park,'Mount Greenwood':Mount_Greenwood,\n",
    "                   'Near North Side':Near_North_Side,'Near South Side':Near_South_Side,'Near West Side':Near_West_Side,\n",
    "                  'New City':New_City,'North Center':North_Center,'North Lawndale':North_Lawndale,'North Park':North_Park,\n",
    "                   'Norwood Park':Norwood_Park,'O\\'Hare':O_Hare,'Oakland':Oakland,\n",
    "                  'Portage Park':Portage_Park,'Pullman':Pullman,'Riverdale':Riverdale,'Rogers Park':Rogers_Park,\n",
    "                   'Roseland':Roseland,'South Chicago':South_Chicago,'South Deering':South_Deering,\n",
    "                  'South Lawndale':South_Lawndale,'South Shore':South_Shore,'The Loop':The_Loop,'Uptown':Uptown,\n",
    "                   'Washington Heights':Washington_Heights,'Washington Park':Washington_Park,\n",
    "                  'West Elsdon':West_Elsdon,'West Englewood':West_Englewood,'West Garfield Park':West_Garfield_Park,\n",
    "                   'West Lawn':West_Lawn,'West Pullman':West_Pullman,'West Ridge':West_Ridge,\n",
    "                  'West Town':West_Town,'Woodlawn':Woodlawn}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "myGeo = Nominatim(user_agent = 'maxwell_burner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_chicago_df(name, neighborhoods):\n",
    "    outlist = []\n",
    "    coordTupSet = set()\n",
    "    for neighborhood in neighborhoods:\n",
    "        success = False\n",
    "        attempts = 0\n",
    "        while(success == False):\n",
    "            try:\n",
    "                address = neighborhood+', Chicago, Illinois'\n",
    "                loc = myGeo.geocode(address)\n",
    "                coordTup = (loc.latitude,loc.longitude)\n",
    "                if(not(coordTup in coordTupSet)):\n",
    "                    coordTupSet.add(coordTup)\n",
    "                    row = {\n",
    "                        'District':name,\n",
    "                        'Neighborhood':neighborhood,\n",
    "                        'Latitude':loc.latitude,\n",
    "                        'Longitude':loc.longitude\n",
    "                          }\n",
    "                    outlist.append(row)\n",
    "                    success = True\n",
    "            except:\n",
    "                if(attempts > 20):\n",
    "                    print('Unable to get coordinates for '+neighborhood)\n",
    "                    success = True\n",
    "                else:\n",
    "                    attempts = attempts + 1\n",
    "    if(len(outlist) > 0):\n",
    "        return outlist\n",
    "    else:\n",
    "        print('Could not get neighborhoods for'+name)\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got Albany Park\n",
      "Got Archer Heights\n",
      "Got Armour Square\n",
      "Unable to get coordinates for Beverly View\n",
      "Got Ashburn\n",
      "Got Auburn Gresham\n",
      "Got Austin\n",
      "Got Avalon Park\n",
      "Got Avondale\n",
      "Got Belmont Cragin\n",
      "Unable to get coordinates for East Beverly\n",
      "Got Beverly\n",
      "Got Bridgeport\n",
      "Got Brighton Park\n",
      "Got Burnside\n",
      "Got Calumet Heights\n",
      "Got Chatham\n",
      "Got Chicago Lawn\n",
      "Unable to get coordinates for Chrysler Village\n",
      "Unable to get coordinates for Clearing East\n",
      "Got Clearing\n",
      "Unable to get coordinates for The Gap\n",
      "Unable to get coordinates for Stateway Gardens\n",
      "Got Douglas\n",
      "Unable to get coordinates for Irving Woods\n",
      "Unable to get coordinates for Schorsch Village\n",
      "Got Dunning\n",
      "Got East Garfield Park\n",
      "Got East Side\n",
      "Got Edgewater\n",
      "Got Edison Park\n",
      "Got Englewood\n",
      "Got Forest Glen\n",
      "Got Fuller Park\n",
      "Got Gage Park\n",
      "Got Garfield Ridge\n",
      "Got Grand Boulevard\n",
      "Unable to get coordinates for Greater Grand Crossing\n",
      "Got Greater Grand Crossing\n",
      "Got Hegewisch\n",
      "Unable to get coordinates for Belmont Gardens\n",
      "Got Hermosa\n",
      "Got Humboldt Park\n",
      "Unable to get coordinates for The Villa\n",
      "Got Irving Park\n",
      "Got Jefferson Park\n",
      "Got Kenwood\n",
      "Unable to get coordinates for Graceland West\n",
      "Unable to get coordinates for Lake View East\n",
      "Unable to get coordinates for South East Ravenswood\n",
      "Got Lake View\n",
      "Unable to get coordinates for Range Triangle\n",
      "Unable to get coordinates for Sheffield Neighbors\n",
      "Unable to get coordinates for West DePaul\n",
      "Unable to get coordinates for Wrightwood Neighbors\n",
      "Got Lincoln Park\n",
      "Got Lincoln Square\n",
      "Got Logan Square\n",
      "Unable to get coordinates for East Pilsen\n",
      "Got Lower West Side\n",
      "Got McKinley Park\n",
      "Got Montclare\n",
      "Got Morgan Park\n",
      "Unable to get coordinates for Talley's Corner\n",
      "Got Mount Greenwood\n",
      "Got Near North Side\n",
      "Got Near South Side\n",
      "Unable to get coordinates for Fulton River District\n",
      "Unable to get coordinates for Tri-Taylor\n",
      "Unable to get coordinates for University Village\n",
      "Got Near West Side\n",
      "Got New City\n",
      "Unable to get coordinates for Saint Ben's\n",
      "Got North Center\n",
      "Got North Lawndale\n",
      "Got North Park\n",
      "Unable to get coordinates for Big Oaks\n",
      "Unable to get coordinates for Norwood Park East\n",
      "Unable to get coordinates for Norwood Park West\n",
      "Unable to get coordinates for Old Norwood\n",
      "Unable to get coordinates for Oriole Park\n",
      "Unable to get coordinates for Union Ridge\n",
      "Could not get neighborhoods forNorwood Park\n",
      "Unable to get coordinates for O'Hare\n",
      "Unable to get coordinates for Schorsch Forest View\n",
      "Could not get neighborhoods forO'Hare\n",
      "Unable to get coordinates for Oakland\n",
      "Could not get neighborhoods forOakland\n",
      "Unable to get coordinates for Portage Park\n",
      "Could not get neighborhoods forPortage Park\n",
      "Unable to get coordinates for Cottage Grove Heights\n",
      "Unable to get coordinates for Pullman\n",
      "Could not get neighborhoods forPullman\n",
      "Unable to get coordinates for Altgeld Gardens\n",
      "Unable to get coordinates for Eden Green\n",
      "Unable to get coordinates for Golden Gate\n",
      "Unable to get coordinates for Riverdale\n",
      "Could not get neighborhoods forRiverdale\n",
      "Unable to get coordinates for Loyola\n",
      "Unable to get coordinates for Rogers Park\n",
      "Could not get neighborhoods forRogers Park\n",
      "Unable to get coordinates for Fernwood\n",
      "Unable to get coordinates for Kensington\n",
      "Unable to get coordinates for Lilydale\n",
      "Unable to get coordinates for Princeton Park\n",
      "Unable to get coordinates for Roseland\n",
      "Unable to get coordinates for Rosemoor\n",
      "Could not get neighborhoods forRoseland\n",
      "Unable to get coordinates for South Chicago\n",
      "Could not get neighborhoods forSouth Chicago\n",
      "Unable to get coordinates for South Deering\n",
      "Could not get neighborhoods forSouth Deering\n",
      "Unable to get coordinates for Little Village\n",
      "Unable to get coordinates for Marhsall Square\n",
      "Unable to get coordinates for South Lawndale\n",
      "Could not get neighborhoods forSouth Lawndale\n",
      "Unable to get coordinates for Jackson Park Highlands\n",
      "Unable to get coordinates for South Shore\n",
      "Could not get neighborhoods forSouth Shore\n",
      "Unable to get coordinates for The Loop\n",
      "Unable to get coordinates for New Eastside\n",
      "Unable to get coordinates for Printer's Row\n",
      "Unable to get coordinates for South Loop\n",
      "Could not get neighborhoods forThe Loop\n",
      "Unable to get coordinates for Buena Park\n",
      "Unable to get coordinates for Clarendon Park\n",
      "Unable to get coordinates for Margate Park\n",
      "Unable to get coordinates for New Chinatown\n",
      "Unable to get coordinates for Sheridan Park\n",
      "Unable to get coordinates for Uptown\n",
      "Could not get neighborhoods forUptown\n",
      "Unable to get coordinates for Brainerd\n",
      "Unable to get coordinates for Longwood Manor\n",
      "Unable to get coordinates for Washington Heights\n",
      "Could not get neighborhoods forWashington Heights\n",
      "Unable to get coordinates for Washington Park\n",
      "Could not get neighborhoods forWashington Park\n",
      "Unable to get coordinates for West Elsdon\n",
      "Could not get neighborhoods forWest Elsdon\n",
      "Unable to get coordinates for West Englewood\n",
      "Could not get neighborhoods forWest Englewood\n",
      "Unable to get coordinates for West Garfield Park\n",
      "Could not get neighborhoods forWest Garfield Park\n",
      "Unable to get coordinates for Ford City\n",
      "Unable to get coordinates for West Lawn\n",
      "Could not get neighborhoods forWest Lawn\n",
      "Unable to get coordinates for West Pullman\n",
      "Could not get neighborhoods forWest Pullman\n",
      "Unable to get coordinates for Nortown\n",
      "Unable to get coordinates for Peterson Park\n",
      "Unable to get coordinates for Rosehill\n",
      "Unable to get coordinates for West Ridge\n",
      "Unable to get coordinates for West Rogers Park\n",
      "Could not get neighborhoods forWest Ridge\n",
      "Unable to get coordinates for East Village\n",
      "Unable to get coordinates for  Noble Square\n",
      "Unable to get coordinates for Pulaski Park\n",
      "Unable to get coordinates for River West\n",
      "Unable to get coordinates for Smith Park\n",
      "Unable to get coordinates for Ukrainian Village\n",
      "Unable to get coordinates for West Town\n",
      "Unable to get coordinates for Wicker Park\n",
      "Unable to get coordinates for Polish Triangle\n",
      "Could not get neighborhoods forWest Town\n",
      "Unable to get coordinates for Woodlawn\n",
      "Unable to get coordinates for West Woodlawn\n",
      "Could not get neighborhoods forWoodlawn\n"
     ]
    }
   ],
   "source": [
    "chicago_df = pd.DataFrame(columns = ['District','Neighborhood','Latitude','Longitude'])\n",
    "for key in list(community_areas.keys()):\n",
    "    get = build_chicago_df(key, community_areas[key])\n",
    "    if(get != 0):\n",
    "        print('Got '+key)\n",
    "        chicago_df = chicago_df.append(get, ignore_index = True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B. Create Database of Chicago Venues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLIENT_ID = 'Q4RKQ5QDH2EJLHQB0X1HH5YGWP02VKIM3Y0GFIPLWTXQ1VIA'\n",
    "CLIENT_SECRET = 'P4ORBZGRWND3H0FE4Z4URXSMOBTFCXQ1ICGE5HK02U4PEZ0J'\n",
    "VERSION = '20190420'\n",
    "\n",
    "\n",
    "#Function to get venues for each Seattle neighborhood\n",
    "def get_venues(districts, neighborhoods, latitudes, longitudes):\n",
    "    venue_df = pd.DataFrame(columns = ['Name','Venue_Category',\n",
    "                                       'Neighborhood','District','Latitude','Longitude'])\n",
    "    venue_dl = []\n",
    "    id_set = set()\n",
    "    \n",
    "    for district, neighborhood, latitude, longitude in zip(districts, neighborhoods, latitudes, longitudes):\n",
    "        url = 'https://api.foursquare.com/v2/venues/explore?client_id={}&client_secret={}&v={}&ll={},{}&radius={}&limit={}'\\\n",
    "        .format(\n",
    "            CLIENT_ID,\n",
    "            CLIENT_SECRET,\n",
    "            VERSION,\n",
    "            latitude,\n",
    "            longitude,\n",
    "            5000,\n",
    "            20000\n",
    "        )\n",
    "        results = requests.get(url).json()\n",
    "        \n",
    "        try:\n",
    "            results = results['response']['groups'][0]['items']\n",
    "            for v in results:\n",
    "                venue_id = v['venue']['id']\n",
    "                if(not(venue_id in id_set)):\n",
    "                    try:\n",
    "                        venue = {\n",
    "                            'Name':v['venue']['name'],\n",
    "                            'Venue_Category':v['venue']['categories'][0]['name'],\n",
    "                            'Neighborhood':neighborhood,\n",
    "                            'District':district,\n",
    "                            'Latitude':v['venue']['location']['lat'],\n",
    "                            'Longitude':v['venue']['location']['lng']\n",
    "                        }\n",
    "                        id_set.add(venue_id)\n",
    "                        venue_dl.append(venue)\n",
    "                    except Exception as e:\n",
    "                        print('Problem getting venue from '+neighborhood+', '+district)\n",
    "                        print(e)\n",
    "        except Exception as e:\n",
    "            print('Error: Problem with '+neighborhood+', '+district)\n",
    "            print(e)\n",
    "            \n",
    "            \n",
    "    venue_df = venue_df.append(venue_dl, ignore_index = True)\n",
    "    return venue_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ConnectionError",
     "evalue": "HTTPSConnectionPool(host='api.foursquare.com', port=443): Max retries exceeded with url: /v2/venues/explore?client_id=Q4RKQ5QDH2EJLHQB0X1HH5YGWP02VKIM3Y0GFIPLWTXQ1VIA&client_secret=P4ORBZGRWND3H0FE4Z4URXSMOBTFCXQ1ICGE5HK02U4PEZ0J&v=20190420&ll=41.9703294,-87.7159915&radius=5000&limit=20000 (Caused by NewConnectionError('<urllib3.connection.VerifiedHTTPSConnection object at 0x000001D6B8FD6E48>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mgaierror\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\urllib3\\connection.py\u001b[0m in \u001b[0;36m_new_conn\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    158\u001b[0m             conn = connection.create_connection(\n\u001b[1;32m--> 159\u001b[1;33m                 (self._dns_host, self.port), self.timeout, **extra_kw)\n\u001b[0m\u001b[0;32m    160\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\urllib3\\util\\connection.py\u001b[0m in \u001b[0;36mcreate_connection\u001b[1;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 57\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mres\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msocket\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetaddrinfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhost\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mport\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfamily\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msocket\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSOCK_STREAM\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     58\u001b[0m         \u001b[0maf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msocktype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mproto\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcanonname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msa\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\socket.py\u001b[0m in \u001b[0;36mgetaddrinfo\u001b[1;34m(host, port, family, type, proto, flags)\u001b[0m\n\u001b[0;32m    747\u001b[0m     \u001b[0maddrlist\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 748\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mres\u001b[0m \u001b[1;32min\u001b[0m \u001b[0m_socket\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetaddrinfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhost\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mport\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfamily\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mproto\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    749\u001b[0m         \u001b[0maf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msocktype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mproto\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcanonname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msa\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mgaierror\u001b[0m: [Errno 11001] getaddrinfo failed",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mNewConnectionError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    599\u001b[0m                                                   \u001b[0mbody\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 600\u001b[1;33m                                                   chunked=chunked)\n\u001b[0m\u001b[0;32m    601\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[1;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[0;32m    342\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 343\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_conn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    344\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mSocketTimeout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mBaseSSLError\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36m_validate_conn\u001b[1;34m(self, conn)\u001b[0m\n\u001b[0;32m    838\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'sock'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# AppEngine might not have  `.sock`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 839\u001b[1;33m             \u001b[0mconn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    840\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\urllib3\\connection.py\u001b[0m in \u001b[0;36mconnect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    300\u001b[0m         \u001b[1;31m# Add certificate verification\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 301\u001b[1;33m         \u001b[0mconn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_new_conn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    302\u001b[0m         \u001b[0mhostname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhost\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\urllib3\\connection.py\u001b[0m in \u001b[0;36m_new_conn\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    167\u001b[0m             raise NewConnectionError(\n\u001b[1;32m--> 168\u001b[1;33m                 self, \"Failed to establish a new connection: %s\" % e)\n\u001b[0m\u001b[0;32m    169\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNewConnectionError\u001b[0m: <urllib3.connection.VerifiedHTTPSConnection object at 0x000001D6B8FD6E48>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mMaxRetryError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\requests\\adapters.py\u001b[0m in \u001b[0;36msend\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    448\u001b[0m                     \u001b[0mretries\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_retries\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 449\u001b[1;33m                     \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    450\u001b[0m                 )\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    637\u001b[0m             retries = retries.increment(method, url, error=e, _pool=self,\n\u001b[1;32m--> 638\u001b[1;33m                                         _stacktrace=sys.exc_info()[2])\n\u001b[0m\u001b[0;32m    639\u001b[0m             \u001b[0mretries\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\urllib3\\util\\retry.py\u001b[0m in \u001b[0;36mincrement\u001b[1;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[0;32m    397\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mnew_retry\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_exhausted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 398\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mMaxRetryError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_pool\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merror\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mResponseError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcause\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    399\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMaxRetryError\u001b[0m: HTTPSConnectionPool(host='api.foursquare.com', port=443): Max retries exceeded with url: /v2/venues/explore?client_id=Q4RKQ5QDH2EJLHQB0X1HH5YGWP02VKIM3Y0GFIPLWTXQ1VIA&client_secret=P4ORBZGRWND3H0FE4Z4URXSMOBTFCXQ1ICGE5HK02U4PEZ0J&v=20190420&ll=41.9703294,-87.7159915&radius=5000&limit=20000 (Caused by NewConnectionError('<urllib3.connection.VerifiedHTTPSConnection object at 0x000001D6B8FD6E48>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mConnectionError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-fc30b8bb42e8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#Create and preview venue dataframe\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mv_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_venues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchicago_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'District'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mchicago_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Neighborhood'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mchicago_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Latitude'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mchicago_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Longitude'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mv_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-6-6f05254488e0>\u001b[0m in \u001b[0;36mget_venues\u001b[1;34m(districts, neighborhoods, latitudes, longitudes)\u001b[0m\n\u001b[0;32m     22\u001b[0m             \u001b[1;36m20000\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m         )\n\u001b[1;32m---> 24\u001b[1;33m         \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\requests\\api.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(url, params, **kwargs)\u001b[0m\n\u001b[0;32m     73\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m     \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msetdefault\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'allow_redirects'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 75\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mrequest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'get'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     76\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\requests\\api.py\u001b[0m in \u001b[0;36mrequest\u001b[1;34m(method, url, **kwargs)\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[1;31m# cases, and look like a memory leak in others.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0msessions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 60\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     61\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\requests\\sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[0;32m    531\u001b[0m         }\n\u001b[0;32m    532\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 533\u001b[1;33m         \u001b[0mresp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    534\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    535\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\requests\\sessions.py\u001b[0m in \u001b[0;36msend\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    644\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    645\u001b[0m         \u001b[1;31m# Send the request\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 646\u001b[1;33m         \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    647\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    648\u001b[0m         \u001b[1;31m# Total elapsed time of the request (approximately)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\requests\\adapters.py\u001b[0m in \u001b[0;36msend\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    514\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mSSLError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    515\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 516\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    517\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    518\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mClosedPoolError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mConnectionError\u001b[0m: HTTPSConnectionPool(host='api.foursquare.com', port=443): Max retries exceeded with url: /v2/venues/explore?client_id=Q4RKQ5QDH2EJLHQB0X1HH5YGWP02VKIM3Y0GFIPLWTXQ1VIA&client_secret=P4ORBZGRWND3H0FE4Z4URXSMOBTFCXQ1ICGE5HK02U4PEZ0J&v=20190420&ll=41.9703294,-87.7159915&radius=5000&limit=20000 (Caused by NewConnectionError('<urllib3.connection.VerifiedHTTPSConnection object at 0x000001D6B8FD6E48>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))"
     ]
    }
   ],
   "source": [
    "#Create and preview venue dataframe\n",
    "v_df = get_venues(chicago_df['District'],chicago_df['Neighborhood'],chicago_df['Latitude'],chicago_df['Longitude'])\n",
    "v_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C. Create a Database of Chicago Neighborhoods with Number of Each Venue Category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "venue_categories = list(set(v_df['Venue_Category']))\n",
    "venueCount_df = pd.DataFrame(columns = ['Neighborhood_'] + venue_categories)\n",
    "\n",
    "venueCount_dl = []\n",
    "\n",
    "for neighborhood in chicago_df.index:\n",
    "    vCount_dict = {'Neighborhood_':neighborhood}\n",
    "    for category in venue_categories:\n",
    "        vCount = sum(v_df.loc[(v_df['Neighborhood']==neighborhood),:]['Venue_Category']==category)\n",
    "        vCount_dict.update({category: vCount})\n",
    "    venueCount_dl.append(vCount_dict)\n",
    "\n",
    "venueCount_df = venueCount_df.append(venueCount_dl)\n",
    "venueCount_df = venueCount_df.set_index('Neighborhood_')\n",
    "venueCount_df.index.name = 'Neighborhood'\n",
    "venueCount_df = venueCount_df.astype(int)\n",
    "venueCount_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.value_counts(IR_Bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extra for working on program: Create/retrieve csv\n",
    "v_df.to_csv(r'C:\\Users\\Maxwell Burner\\Desktop\\Data_Science\\Lecture Notes\\chicago_venues_df.csv')\n",
    "chicago_df.to_csv(r'C:\\Users\\Maxwell Burner\\Desktop\\Data_Science\\Lecture Notes\\chicago_df.csv')\n",
    "venueCount_df.to_csv(r'C:\\Users\\Maxwell Burner\\Desktop\\Data_Science\\Lecture Notes\\venueCount_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bypass: Copy Dataframes from Github raws\n",
    "v_df = pd.read_csv(r'https://raw.githubusercontent.com/burnermax37/Coursera_Capstone/master/chicago_venues_df.csv').iloc[:,1:]\n",
    "chicago_df = pd.read_csv(r'https://raw.githubusercontent.com/burnermax37/Coursera_Capstone/master/chicago_df.csv')\n",
    "venueCount_df = pd.read_csv(r'https://raw.githubusercontent.com/burnermax37/Coursera_Capstone/master/venueCount_df.csv')\n",
    "\n",
    "chicago_df = chicago_df.set_index('Neighborhood', drop = True)\n",
    "venueCount_df = venueCount_df.set_index('Neighborhood', drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "venueCount_df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# II. Predict Location Suitability with Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A. Transform Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The base target value is numeric, a count of how many Italian Restaurants are present in a neighborhood. However, this variable is discrete rather than continuous, and therefore probably be predicted using classification methods rather than regression. To facilitate this, and make the implication clear, the attribute containing number of italian restaurants is mapped to a new categorical variable according to the following legend:\n",
    "\n",
    "0 Italian restaurants: Very Poor\n",
    "\n",
    "1 Italian restaurant: Poor\n",
    "\n",
    "2 Italian restaurant: Okay\n",
    "\n",
    "3 Italian restaurants: Good\n",
    "\n",
    "4 Italian restaurants: Very Good\n",
    "\n",
    "5 Italian restaurants: Excellent\n",
    "\n",
    "6 Italian restaurants: Perfect\n",
    "\n",
    "Alternately, a Boolean approach can be used, with 1 indicating a neighborhood with more than one Italian restaurants, and 0 indicating an neighborhood with zero or one Italian Restaurants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Assign ratings to neighborhoods based on number of Italian restaurants\n",
    "IR_Ratings = venueCount_df['Italian Restaurant']\n",
    "IR_Ratings = IR_Ratings.replace({0:'Very Poor', 1:'Poor', 2:'Okay', 3:'Good', 4:'Very Good', 5:'Excellent', 6:'Perfect'})\n",
    "\n",
    "pd.value_counts(IR_Ratings).loc[['Very Poor', 'Poor', 'Okay', 'Good', 'Very Good', 'Excellent', 'Perfect']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "order = ['Very Poor','Poor','Okay','Good','Very Good','Excellent','Perfect']\n",
    "fig = py.figure(figsize = (15,7))\n",
    "ax = pd.value_counts(IR_Ratings).loc[order].plot(kind = 'bar')\n",
    "ax.set_title('Number of Neighborhoods by Multi-Label IR Rating', fontsize = 'xx-large')\n",
    "ax.set_xlabel('IR Rating', fontsize = 'x-large')\n",
    "ax.set_ylabel('Number of Neighborhoods', fontsize = 'x-large')\n",
    "py.xticks(fontsize = 'x-large')\n",
    "py.yticks(fontsize = 'x-large')\n",
    "ax.set_yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig = py.figure(figsize = (15,7))\n",
    "ax = pd.value_counts(IR_Bool).plot(kind = 'bar')\n",
    "ax.set_title('Number of Neighborhoods by Single-Label IR Rating', fontsize = 'xx-large')\n",
    "ax.set_xlabel('IR Rating', fontsize = 'x-large')\n",
    "ax.set_ylabel('Number of Neighborhoods', fontsize = 'x-large')\n",
    "py.xticks(fontsize = 'x-large')\n",
    "py.yticks(fontsize = 'x-large')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IR_Bool = venueCount_df['Italian Restaurant']\n",
    "IR_Bool = IR_Bool.replace({1:0,2:1,3:1,4:1,5:1,6:1})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xraw = venueCount_df.drop('Italian Restaurant', axis=1).values\n",
    "ss = StandardScaler()\n",
    "X = ss.fit_transform(Xraw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A. K-Nearest Neighbors Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#KNeighbors Validation of K-Value\n",
    "KN_val_df = pd.DataFrame(columns = ['K Value', 'Accuracy Score Median','Accuracy Score Mean', 'Accuracy Score StdDev',\n",
    "                                   'Accuracy Score Skew'])\n",
    "KN_val_dl = []\n",
    "\n",
    "\n",
    "for k in range(1,20):\n",
    "\n",
    "    accuracy_list = []\n",
    "    testK = KNeighborsClassifier(n_neighbors = k)\n",
    "    for r in range(200):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, IR_Ratings, test_size = 0.3, random_state = r)\n",
    "        testK.fit(X_train, y_train)\n",
    "        y_hat = testK.predict(X_test)\n",
    "        accuracy_list.append(accuracy_score(y_test, y_hat))\n",
    "    kMean = round(np.mean(accuracy_list),2)\n",
    "    kMedian = round(np.median(accuracy_list),2)\n",
    "    kStdDev = round(np.std(accuracy_list, ddof = 19),2)\n",
    "    kSkew = round( ((kMedian - kMean)*3/kStdDev),2  )\n",
    "    KN_val_dl.append({'K Value':k,'Accuracy Score Median':kMedian, 'Accuracy Score Mean':kMean,\n",
    "                      'Accuracy Score StdDev':kStdDev,\n",
    "                      'Accuracy Score Skew':kSkew\n",
    "                     })\n",
    "        \n",
    "\n",
    "KN_val_df = KN_val_df.append(KN_val_dl, ignore_index = True)\n",
    "KN_val_df = KN_val_df.set_index('K Value')\n",
    "KN_val_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig = py.figure(figsize = (15,7))\n",
    "pl = py.errorbar(KN_val_df.index.tolist(),KN_val_df['Accuracy Score Mean'], yerr = KN_val_df['Accuracy Score StdDev'],\n",
    "           )\n",
    "py.ylim(0.6,1)\n",
    "py.xlabel('Model K Value', fontsize = 'x-large')\n",
    "py.ylabel('Accuracy Score Mean', fontsize = 'x-large')\n",
    "py.title('Accuracy Score Mean versus Model K Value (Multi-Label K-Nearest Neighbors)', fontsize = 'xx-large')\n",
    "py.xticks([2,4,6,8,10,12,14,16,18])\n",
    "pl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mean accuracy score was 0.78 (for k =< 2) or 0.83 (for k > 2). Accuracy score standard deviation was constant at 0.04 when calculated over 200 attempts at creating a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myK = KNeighborsClassifier(n_neighbors = 3)\n",
    "myK.fit(X, IR_Ratings)\n",
    "y_hat = myK.predict(X)\n",
    "accuracy_score(IR_Ratings, y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#KNeighbors Validation of K-Value, Single-Label\n",
    "KN_bool_df = pd.DataFrame(columns = ['K Value', 'Accuracy Score Median','Accuracy Score Mean', 'Accuracy Score StdDev',\n",
    "                                   'Accuracy Score Skew'])\n",
    "KN_bool_dl = []\n",
    "\n",
    "\n",
    "for k in range(1,20):\n",
    "\n",
    "    accuracy_list = []\n",
    "    testK = KNeighborsClassifier(n_neighbors = k)\n",
    "    for r in range(200):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, IR_Bool, test_size = 0.3, random_state = r)\n",
    "        testK.fit(X_train, y_train)\n",
    "        y_hat = testK.predict(X_test)\n",
    "        accuracy_list.append(accuracy_score(y_test, y_hat))\n",
    "    kMean = round(np.mean(accuracy_list),2)\n",
    "    kMedian = round(np.median(accuracy_list),2)\n",
    "    kStdDev = round(np.std(accuracy_list, ddof = 19),2)\n",
    "    kSkew = round( ((kMedian - kMean)*3/kStdDev),2  )\n",
    "    KN_bool_dl.append({'K Value':k,'Accuracy Score Median':kMedian, 'Accuracy Score Mean':kMean,\n",
    "                      'Accuracy Score StdDev':kStdDev,\n",
    "                      'Accuracy Score Skew':kSkew\n",
    "                     })\n",
    "        \n",
    "\n",
    "KN_bool_df = KN_bool_df.append(KN_val_dl, ignore_index = True)\n",
    "KN_bool_df = KN_bool_df.set_index('K Value')\n",
    "KN_bool_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig = py.figure(figsize = (15,7))\n",
    "pl = py.errorbar(KN_bool_df.index.tolist(),KN_bool_df['Accuracy Score Mean'], yerr = KN_bool_df['Accuracy Score StdDev'],\n",
    "           )\n",
    "py.ylim(0.6,1)\n",
    "py.xlabel('Model K Value', fontsize = 'x-large')\n",
    "py.ylabel('Accuracy Score Mean', fontsize = 'x-large')\n",
    "py.title('Accuracy Score Mean versus Model K Value (Single Label K-Nearest Neighbors)', fontsize = 'xx-large')\n",
    "py.xticks([2,4,6,8,10,12,14,16,18])\n",
    "pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myK = KNeighborsClassifier(n_neighbors = 2)\n",
    "myK.fit(X, IR_Bool)\n",
    "y_hat = myK.predict(X)\n",
    "accuracy_score(IR_Bool, y_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B. Decision Tree Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Decision Tree Validation of Tree Depth, Multi-Label Approach\n",
    "treeVal_df = pd.DataFrame(columns = ['Maximum Depth','Accuracy Score Median', 'Accuracy Score Mean',\n",
    "                                     'Accuracy Score StdDev', 'Accuracy Score Skew'])\n",
    "treeVal_dl = []\n",
    "\n",
    "for k in range(1,20):\n",
    "    accuracy_list = []\n",
    "    testTree = DecisionTreeClassifier(criterion = 'entropy', max_depth = k)\n",
    "    for r in range(200):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, IR_Ratings, test_size = 0.3, random_state = r)\n",
    "        testTree.fit(X_train, y_train)\n",
    "        y_hat = testTree.predict(X_test)\n",
    "        accuracy_list.append(accuracy_score(y_test, y_hat))\n",
    "    kMean = round(np.mean(accuracy_list),2)\n",
    "    kMedian = round(np.median(accuracy_list),2)\n",
    "    kStdDev = round(np.std(accuracy_list, ddof = 19),2)\n",
    "    kSkew = round(((kMedian - kMean)*3/kStdDev),2)\n",
    "    treeVal_dl.append({'Maximum Depth':k,\n",
    "                       'Accuracy Score Median':kMedian,\n",
    "                       'Accuracy Score Mean':kMean, \n",
    "                       'Accuracy Score StdDev':kStdDev,\n",
    "                      'Accuracy Score Skew':kSkew})\n",
    "\n",
    "\n",
    "treeVal_df = treeVal_df.append(treeVal_dl, ignore_index = True)\n",
    "treeVal_df = treeVal_df.set_index('Maximum Depth')\n",
    "treeVal_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "py.figure(figsize = (15,7))\n",
    "py.errorbar(treeVal_df.index.tolist(),treeVal_df['Accuracy Score Mean'],yerr = treeVal_df['Accuracy Score StdDev'])\n",
    "py.xlabel('Maximum Depth of Tree', fontsize = 'x-large')\n",
    "py.ylabel('Accuracy Score Mean', fontsize = 'x-large')\n",
    "py.ylim(0.6,1)\n",
    "py.xticks([2,4,6,8,10,12,14,16,18])\n",
    "py.title('Accuracy Score Mean versus Maximum Tree Depth (Multi-Label Decision Tree Classifier)'\\\n",
    "        , fontsize = 'xx-large')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Decision Tree Validation of Tree Depth, Boolean Approach\n",
    "treeBool_df = pd.DataFrame(columns = ['Maximum Depth','Accuracy Score Median', 'Accuracy Score Mean',\n",
    "                                     'Accuracy Score StdDev', 'Accuracy Score Skew'])\n",
    "\n",
    "treeBool_dl = []\n",
    "\n",
    "for k in range(1,20):\n",
    "    accuracy_list = []\n",
    "    testTree = DecisionTreeClassifier(criterion = 'entropy', max_depth = k)\n",
    "    for r in range(200):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, IR_Bool, test_size = 0.3, random_state = r)\n",
    "        testTree.fit(X_train, y_train)\n",
    "        y_hat = testTree.predict(X_test)\n",
    "        accuracy_list.append(accuracy_score(y_test, y_hat))\n",
    "    kMean = round(np.mean(accuracy_list),2)\n",
    "    kMedian = round(np.median(accuracy_list),2)\n",
    "    kStdDev = round(np.std(accuracy_list, ddof = 19),2)\n",
    "    kSkew = round(((kMedian - kMean)*3/kStdDev),2)\n",
    "    treeBool_dl.append({'Maximum Depth':k,\n",
    "                       'Accuracy Score Median':kMedian,\n",
    "                       'Accuracy Score Mean':kMean, \n",
    "                       'Accuracy Score StdDev':kStdDev,\n",
    "                      'Accuracy Score Skew':kSkew})\n",
    "\n",
    "\n",
    "treeBool_df = treeBool_df.append(treeBool_dl, ignore_index = True)\n",
    "treeBool_df = treeBool_df.set_index('Maximum Depth')\n",
    "treeBool_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "py.figure(figsize = (15,7))\n",
    "py.errorbar(treeBool_df.index.tolist(),treeBool_df['Accuracy Score Mean'],yerr = treeBool_df['Accuracy Score StdDev'])\n",
    "py.xlabel('Maximum Depth of Tree', fontsize = 'x-large')\n",
    "py.ylabel('Accuracy Score Mean', fontsize = 'x-large')\n",
    "py.ylim(0.8,1)\n",
    "py.xticks([2,4,6,8,10,12,14,16,18])\n",
    "py.title('Accuracy Score Mean versus Maximum Tree Depth (Single-Label Decision Tree Classifier)',\n",
    "        fontsize = 'xx-large')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "myTree = DecisionTreeClassifier(criterion = 'entropy', max_depth = 2)\n",
    "myTree.fit(X,IR_Ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = myTree.predict(X)\n",
    "accuracy_score(IR_Ratings, y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hold = StringIO()\n",
    "features = venueCount_df.drop('Italian Restaurant', axis = 1).columns\n",
    "classes = ['Very Poor', 'Poor', 'Okay', 'Good', 'Very Good', 'Excellent', 'Perfect']\n",
    "\n",
    "out = tree.export_graphviz(myTree, feature_names = features, class_names = classes, out_file = hold, filled = True,\n",
    "                   special_characters = True, rotate = False)\n",
    "\n",
    "graph = pydotplus.graph_from_dot_data(hold.getvalue())\n",
    "Image(graph.create_png())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boolTree = DecisionTreeClassifier(criterion = 'entropy', max_depth =2)\n",
    "boolTree.fit(X, IR_Bool.astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hold = StringIO()\n",
    "features = venueCount_df.drop('Italian Restaurant', axis = 1).columns\n",
    "bool_classes = ['0','1']\n",
    "\n",
    "out = tree.export_graphviz(boolTree, feature_names = features, class_names = bool_classes, out_file = hold, filled = True,\n",
    "                   special_characters = True, rotate = False)\n",
    "\n",
    "graph = pydotplus.graph_from_dot_data(hold.getvalue())\n",
    "Image(graph.create_png())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = boolTree.predict(X)\n",
    "accuracy_score(IR_Bool.astype(str), y_hat)\n",
    "y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## C. Logistic Regression Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Logistic Regression Validation of Regularization Strength, Multi-Label Approach\n",
    "\n",
    "\n",
    "logVal_df = pd.DataFrame(columns = ['C Value','Accuracy Score Median','Accuracy Score Mean', 'Accuracy Score StdDev',\n",
    "                                   'Accuracy Score Skew'])\n",
    "logVal_dl = []\n",
    "\n",
    "for k in [1,10,15,20,30,50,100,1000,2000]:\n",
    "    loss_list = []\n",
    "    testLog = LogisticRegression(C = k, solver = 'newton-cg', multi_class = 'ovr')\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, IR_Ratings, test_size = 0.3, random_state = r)\n",
    "        testLog.fit(X_train, y_train)\n",
    "        y_hat = testLog.predict(X_test)\n",
    "        accuracy = accuracy_score(y_test, y_hat)\n",
    "        loss_list.append(accuracy)\n",
    "    loss_mean = round(np.mean(loss_list),2)\n",
    "    loss_median = round(np.median(loss_list),2)\n",
    "    loss_std = round(np.std(loss_list, ddof = 19),2)\n",
    "    loss_skew = round( ((loss_median - loss_mean)*3/loss_std),2 )\n",
    "    logVal_dl.append({'C Value':k, 'Accuracy Score Median':loss_median,\n",
    "                      'Accuracy Score Mean':loss_mean,'Accuracy Score StdDev':loss_std,\n",
    "                     'Accuracy Score Skew':loss_skew})\n",
    "    \n",
    "logVal_df = logVal_df.append(logVal_dl, ignore_index = True)\n",
    "logVal_df = logVal_df.set_index('C Value')\n",
    "logVal_df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "py.figure(figsize = (15,7))\n",
    "py.errorbar(logVal_df.index.tolist(), logVal_df['Accuracy Score Mean'], yerr = logVal_df['Accuracy Score StdDev'])\n",
    "py.xlabel('C-Value', fontsize = 'x-large')\n",
    "py.ylabel('Mean Accuracy Score', fontsize = 'x-large')\n",
    "py.ylim(0,1)\n",
    "py.xscale('log')\n",
    "py.xticks(fontsize = 'x-large')\n",
    "py.yticks(fontsize = 'x-large')\n",
    "py.title('Mean Accuracy Score versus C-Value (Multi-Label Logistic Regression)', fontsize = 'xx-large')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myLog = LogisticRegression(C = 1000, solver = 'newton-cg', multi_class = 'ovr')\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, IR_Ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Logistic Regression Validation of Regularization Strength, Single-Label Approach\n",
    "\n",
    "\n",
    "logBool_df = pd.DataFrame(columns = ['C Value','Accuracy Score Mean','Accuracy Score StdDev',\n",
    "                                   'Log Loss Mean', 'Log Loss StdDev'])\n",
    "logBool_dl = []\n",
    "\n",
    "for k in [1,10,15,20,30,50,100,1000,2000]:\n",
    "    aL = []\n",
    "    llL = []\n",
    "    testLog = LogisticRegression(C = k, solver = 'liblinear', multi_class = 'ovr')\n",
    "    for r in range(20):\n",
    "        good_split = False\n",
    "        while(good_split == False):\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X, IR_Bool, test_size = 0.3, random_state = r)\n",
    "            if(set(y_train) == set(y_test)):\n",
    "                good_split = True\n",
    "                testLog.fit(X_train, y_train)\n",
    "                y_hat = testLog.predict(X_test)\n",
    "                y_p = testLog.predict_proba(X_test)\n",
    "                acc = accuracy_score(y_test, y_hat)\n",
    "                ll = log_loss(y_test, y_p)\n",
    "                aL.append(acc)\n",
    "                llL.append(ll)\n",
    "            else:\n",
    "                print('Retry')\n",
    "    a_mean = round(np.mean(aL),2)\n",
    "    a_std = round(np.std(aL, ddof = 19),2)\n",
    "    ll_mean = round(np.mean(llL),2)\n",
    "    ll_std = round(np.std(llL, ddof = 19),2)    \n",
    "\n",
    "\n",
    "    logBool_dl.append({'C Value':k,\n",
    "                       'Accuracy Score Mean':a_mean, 'Accuracy Score StdDev':a_std,\n",
    "                       'Log Loss Mean':ll_mean,'Log Loss StdDev':ll_std,\n",
    "\n",
    "                      })\n",
    "    \n",
    "logBool_df = logBool_df.append(logBool_dl, ignore_index = True)\n",
    "logBool_df = logBool_df.set_index('C Value')\n",
    "logBool_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "py.figure(figsize = (15,7))\n",
    "py.errorbar(logBool_df.index.tolist(), logBool_df['Accuracy Score Mean'], yerr = logBool_df['Accuracy Score StdDev'])\n",
    "py.xlabel('C-Value', fontsize = 'x-large')\n",
    "py.ylabel('Mean Accuracy Score', fontsize = 'x-large')\n",
    "py.ylim(0,1)\n",
    "py.yticks(fontsize = 'x-large')\n",
    "py.xticks(fontsize = 'x-large')\n",
    "py.xscale('log')\n",
    "py.title('Mean Accuracy Score versus C-Value (Single-Label Logistic Regression)', fontsize = 'xx-large')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "py.figure(figsize = (15,7))\n",
    "py.errorbar(logBool_df.index.tolist(), logBool_df['Log Loss Mean'], yerr = logBool_df['Log Loss StdDev'])\n",
    "py.xlabel('C-Value', fontsize = 'x-large')\n",
    "py.ylabel('Mean Log Loss', fontsize = 'x-large')\n",
    "py.yticks(fontsize = 'x-large')\n",
    "py.xticks(fontsize = 'x-large')\n",
    "py.xscale('log')\n",
    "py.title('Mean Log Loss versus C-Value (Single-Label Logistic Regression)', fontsize = 'xx-large')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myLog = LogisticRegression(C = 1000, solver = 'liblinear', multi_class = 'ovr')\n",
    "myLog.fit(X, IR_Bool)\n",
    "y_hat = myLog.predict(X)\n",
    "print(log_loss(IR_Bool, y_hat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IV. Describe Characteristics of Neighborhoods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "venueCount_df.corr()['Italian Restaurant'].sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig = py.figure(figsize = (15,7))\n",
    "axCorr = venueCount_df.corr()['Italian Restaurant'].sort_values(ascending = False)[1:11].plot(kind = 'bar')\n",
    "axCorr.set_title('Venue Categories with Highest Correlation to Italian Restaurant Prevalence',\n",
    "                fontsize = 'xx-large')\n",
    "axCorr.set_ylabel('Correlation Constant', fontsize = 'x-large')\n",
    "axCorr.set_xlabel('Venue Category', fontsize = 'x-large')\n",
    "axCorr.set_ylim(0.4,0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fra = venueCount_df.loc[(venueCount_df['Italian Restaurant'] > 3),:].transpose()\n",
    "outDf = pd.DataFrame(columns = fra.columns)\n",
    "\n",
    "\n",
    "for neighborhood in fra1.columns:\n",
    "    ser = pd.Series(index = fra.index, data = fra[neighborhood]).sort_values(ascending = False)\n",
    "    tuL = []\n",
    "    for i in range(5):\n",
    "        tup = (ser.index[i],ser.values[i])\n",
    "        tuL.append(tup)\n",
    "\n",
    "    outDf.loc[:,neighborhood] = tuL\n",
    "\n",
    "outDf.index = ['1st Category, Count',\n",
    "               '2nd Category, Count',\n",
    "               '3rd Category, Count',\n",
    "               '4th Category, Count',\n",
    "               '5th Category, Count']\n",
    "outDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cgroups = venueCount_df.copy()\n",
    "cgroups = venueCount_df.groupby(IR_Ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = cgroups.get_group('Very Poor').mean(axis = 0).sort_values(ascending = False).head(5).plot(kind = 'bar')\n",
    "ax.set_title('Most Common Venues in Chicago Neighborhoods with no Italian Restaurants')\n",
    "ax.set_ylabel('Average Number of Venues')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = cgroups.get_group('Poor').mean(axis = 0).sort_values(ascending = False).head(5).plot(kind = 'bar')\n",
    "ax.set_title('Most Common Venues in Chicago Neighborhoods with One Italian Restaurants')\n",
    "ax.set_ylabel('Average Number of Venues')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = cgroups.get_group('Okay').mean(axis = 0).sort_values(ascending = False).head(5).plot(kind = 'bar')\n",
    "ax.set_title('Most Common Venues in Chicago Neighborhoods with Two Italian Restaurants')\n",
    "ax.set_ylabel('Average Number of Venues')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = cgroups.get_group('Good').mean(axis = 0).sort_values(ascending = False).head(5).plot(kind = 'bar')\n",
    "ax.set_title('Most Common Venues in Chicago Neighborhoods with Three Italian Restaurants')\n",
    "ax.set_ylabel('Average Number of Venues')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ax = cgroups.get_group('Very Good').mean(axis = 0).sort_values(ascending = False).head(5).plot(kind = 'bar')\n",
    "ax.set_title('Most Common Venues in Chicago Neighborhoods with Four Italian Restaurants')\n",
    "ax.set_ylabel('Average Number of Venues')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ax = cgroups.get_group('Excellent').mean(axis = 0).sort_values(ascending = False).head(5).plot(kind = 'bar')\n",
    "ax.set_title('Most Common Venues in Chicago Neighborhoods with Five Italian Restaurants')\n",
    "ax.set_ylabel('Average Number of Venues')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ax = cgroups.get_group('Perfect').mean(axis = 0).sort_values(ascending = False).head(5).plot(kind = 'bar')\n",
    "ax.set_title('Most Common Venues in Chicago Neighborhoods with Six Italian Restaurants')\n",
    "ax.set_ylabel('Average Number of Venues')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bgroups = venueCount_df.groupby(IR_Bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig = py.figure(figsize = (15,7))\n",
    "ax = bgroups.get_group(0).mean(axis = 0).sort_values(ascending = False).head(5).plot(kind = 'bar')\n",
    "ax.set_title('Most Common Venues in Chicago Neighborhoods with Zero or One Italian Restaurant', fontsize = 'xx-large')\n",
    "ax.set_ylabel('Average Number of Venues per Neighborhood', fontsize = 'x-large')\n",
    "ax.set_xlabel('Venue Category', fontsize = 'x-large')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig = py.figure(figsize = (15,7))\n",
    "ax = bgroups.get_group(1).mean(axis = 0).sort_values(ascending = False).head(5).plot(kind = 'bar')\n",
    "ax.set_title('Most Common Venues in Chicago Neighborhoods with more than One Italian Restaurant', fontsize = 'xx-large')\n",
    "ax.set_ylabel('Average Number of Venues per Neighborhood', fontsize = 'x-large')\n",
    "ax.set_xlabel('Venue Categories', fontsize = 'x-large')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s0 = bgroups.get_group(0).mean(axis = 0)\n",
    "s1 = bgroups.get_group(1).mean(axis = 0)\n",
    "dif = s1 - s0\n",
    "dif2 = dif.sort_values(ascending = False)[1:6]\n",
    "dif2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1['Grocery Store']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = py.figure(figsize = (15,6))\n",
    "ax = dif2.plot(kind = 'bar')\n",
    "ax.set_title('Largest Differences in Mean Venue Cateogry Prevalence by Neighborhood between IRRB Groups',\n",
    "            fontsize = 'xx-large')\n",
    "ax.set_xlabel('Venue Category', fontsize = 'x-large')\n",
    "ax.set_ylabel('Group 1 Prevalance minus Group 0 Prevalence', fontsize = 'x-large')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "venueCount_df.corr()['Italian Restaurant'].sort_values(ascending = False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IV. Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chicago_df = chicago_df.set_index('Neighborhood', drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "center_latitude = v_df['Latitude'].mean()\n",
    "center_longitude = v_df['Longitude'].mean()\n",
    "\n",
    "myMap = folium.Map(location = [center_latitude, center_longitude], zoom_start = 10)\n",
    "\n",
    "for neighborhood in chicago_df.index:\n",
    "    dist = chicago_df.loc[neighborhood,'District']\n",
    "    lat = chicago_df.loc[neighborhood,'Latitude']\n",
    "    long = chicago_df.loc[neighborhood,'Longitude']\n",
    "    rating = IR_Ratings[neighborhood]\n",
    "    \n",
    "    label = '{}, {}: {} Italian Restaurant Rating'.format(neighborhood, dist, rating)\n",
    "    label = folium.Popup(label, parse_html = True)\n",
    "    if(rating == 'Very Poor'):\n",
    "        r_c = 'red'\n",
    "    elif(rating == 'Poor'):\n",
    "        r_c = 'orange'\n",
    "    elif(rating == 'Okay'):\n",
    "        r_c = 'yellow'\n",
    "    elif(rating == 'Good'):\n",
    "        r_c = 'green'\n",
    "    elif(rating == 'Very Good'):\n",
    "        r_c = 'cyan'\n",
    "    elif(rating == 'Excellent'):\n",
    "        r_c = 'blue'\n",
    "    elif(rating == 'Perfect'):\n",
    "        r_c = 'violet'\n",
    "    \n",
    "    folium.CircleMarker(\n",
    "        [lat, long],\n",
    "        radius = 5,\n",
    "        popup = label,\n",
    "        color = r_c,\n",
    "        fill = True,\n",
    "        fill_color = r_c,\n",
    "        fill_opacity = 0.7,\n",
    "        parse_html = False\n",
    "    ).add_to(myMap)\n",
    "myMap    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "center_latitude = v_df['Latitude'].mean()\n",
    "center_longitude = v_df['Longitude'].mean()\n",
    "\n",
    "myBoolMap = folium.Map(location = [center_latitude, center_longitude], zoom_start = 10)\n",
    "\n",
    "for neighborhood in chicago_df.index:\n",
    "    dist = chicago_df.loc[neighborhood,'District']\n",
    "    lat = chicago_df.loc[neighborhood,'Latitude']\n",
    "    long = chicago_df.loc[neighborhood,'Longitude']\n",
    "    rating = IR_Bool[neighborhood]\n",
    "    \n",
    "\n",
    "    if(rating == 0):\n",
    "        r_c = 'red'\n",
    "        ratString = 'Bad'\n",
    "    elif(rating == 1):\n",
    "        r_c = 'green'\n",
    "        ratString = 'Good'\n",
    "    else:\n",
    "        r_c = 'yellow'   \n",
    "    label = '{},{}. Italian Restaurant Rating: {}'.format(neighborhood, dist, ratString)\n",
    "    label = folium.Popup(label, parse_html = True)\n",
    "    folium.CircleMarker(\n",
    "        [lat, long],\n",
    "        radius = 5,\n",
    "        popup = label,\n",
    "        color = r_c,\n",
    "        fill = True,\n",
    "        fill_color = r_c,\n",
    "        fill_opacity = 0.5,\n",
    "        parse_html = False\n",
    "    ).add_to(myBoolMap)\n",
    "\n",
    "myBoolMap    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tup = []\n",
    "for neighborhood in chicago_df.index:\n",
    "    tup.append((chicago_df.loc[neighborhood,'Latitude'], chicago_df.loc[neighborhood, 'Longitude']) )\n",
    "    \n",
    "test = pd.Series(index = chicago_df.index, data = tup)\n",
    "len(list(set(tup)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coordTupSet = set()\n",
    "for neighborhood in chicago_df.index:\n",
    "    coordTup = (chicago_df.loc[neighborhood,'Latitude'],chicago_df.loc[neighborhood,'Longitude'])\n",
    "    if(not(coordTup in coordTupSet)):\n",
    "        coordTupSet.add(coordTup)\n",
    "    else:\n",
    "        chicago_df = chicago_df.drop(neighborhood, axis = 0)\n",
    "chicago_df_raw = chicago_df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
